<div class="container" style="width:700px;">

<br>
<div class="row">
<br>
    <h2><p class="font-weight-bold" style="font-size:30px; margin-top: 20px">논문 분석 Model</p></h2>
</div>
    <div class="row">

    <br>
    </div>
    <div class="row">
    <b> 개요 </b>
        각 의사가 전문분야별로 어떤 전문성을 가지고 있는지 보여주기 위해 논문 data를 사용하였으나,
        이러한 논문들은 전문분야별로 분류되어 있지 않은 경우가 많습니다. 또한 치과의사가 아닌 이상
        논문은 전문분야별로 특징을 알기 힘들고 이해하기도 어려운 전문용어로 구성되어 있습니다.
        통계기반과 추론기반 두가지 방법 모두 접근하여 이를 해결해보려고 하였습니다. <br>
    <br>
        <b>시도된 모델</b>
</div>
    <div class="row">

        <br>
        <br>
        <div class="alert alert-warning" role="alert" style="width: 700px">
                <b>1) PMI based Sentiment Analysis</b>
        </div>

        <b>Accuracy</b> : 57%

    </div>
    <br>
    <div class="row">
    - 통계기반 방법으로 PMI(Pointwise mutual information), 즉 단어간의 관계를 통한 scoring model입니다.
    각 전문분야마다 unique한 Seed가 주어지고, 이 Seed와 각 문서(논문)가 얼마나 유사도를 갖는지에 따라 점수가 매겨지고
        점수가 높은 분야로 classification을 하게 됩니다.<br>
    - Semi-supervised learning이므로 라벨링된 데이터 없이 사용 할 수 있다는 점이 장점입니다. <br>
    - 전문분야별 Seed를 정할 때 모든 논문 Data에 대해 LDA, LSA를 적용하여 각 과별로 토픽을 묶고 Seed를
    추출하려고 시도하였으나 LDA, LSA로는 Seed를 정하는 것에 한계가 있었습니다. <br>
    결국 사람이 직접 보면서 전문분야를 나타내는 Seed를 추출하면서
    labeling된 데이터와 끊임없이 비교해보는 방식으로 진행하였습니다.
    그러나 전문분야에 따라 논문의 개수가 차이가 나기 때문에 같은 개수로 Seed를 맞추는 것이 쉽지 않았습니다. <br>
    - 최종적으로 3개의 전공 과목에 대해서는 80%이상의 정확도를 가지지만 1개의 과목에서는 50%의 정확도를 가졌고
    다른 3개의 전공과목에서는 실제 그 전공과목의 논문 갯수보다 훨씬 많은 갯수로 예측되어 정확도가 상당히 떨어지게 되었습니다.
    </div>

    <br>

    <div class="row">
        <div class="alert alert-warning" role="alert" style="width: 700px">
                <b>2) LSTM</b>
        </div>

        <br>
        <b>Accuracy</b> : 78%
        <br>
        <br>
    </div>
    <div class="row">
    필요한 정보를 얻기 위한 시간 격차에 문제를 가진 RNN 모델의 문제를 극복한 모델입니다.
    RNN에 이전 정보를 담은 cell state를 추가한 gate를 사용합니다.
    LSTM은 나쁘지 않은 성능을 보여주었으나, 논문의 특성상 문맥이 크게 중요하지 않다는 점과
    CNN의 좋은 성능으로 인해 개발에서 제외되었습니다.
    </div>
    <br>
    <div class="row">
        <div class="alert alert-danger" role="alert" style="width: 700px">
                <b>3) CNN for sentence classification</b>
            시스템 적용 모델
        </div>
        <img src="{{ url_for('static',filename='CNN_model.png') }}" width="600px" height = 300px alt="CNN_Model">
        <img src="{{ url_for('static',filename='cnn_skel.png') }}" width="100px" height = 300px alt="CNN_Model">
        <br>
        <b>Accuracy</b> : 89%
        <br>
        <br>
    </div>
    <div class="row">
        - CNN은 자연어처리에서 매우 빠른 속도를 보여주는 기법입니다. 문맥보다는 n-gram같이 단어의 주변분포를 고려하지만
        그럼에도 좋은 성능을 보여주고 있습니다.<br>
        - 단어들은 vector로 Embedding되고 여러 컨볼루션을 거쳐서 필터수만큼 각 feature를 만들게 됩니다.
        이로 만들어진 feature mape이 Neural-network를 거쳐 classfication을 하게 됩니다. <br>
        이 후 모델은 의사들의 논문을 각 전문분야별로 분류하게 됩니다. <br>
        - Model layer에는 Conv1D와 GlobalMaxPooling1D가 사용되었습니다. <br>
        - 정답데이터로는 labeling된 해외 치의학계 논문을 사용하였습니다.<br>
        - 논문 초록의 경우 문맥이나 대화흐름이 중요한 구어체가 아니라 문장에서 특색있는 단어가
        classification에 더 중요한 요소로 작용하는 문어체가 많아 높은 정확도를 낼 수 있었습니다. <br><br>
    </div>
    <br>
    <br>

    <div class="row">
    <b>향후 방향</b>
    </div>
    <div class="row">
        시스템에서는 각종 feature들로부터 도출된 각 의사가 가지는 속성(논문, 전문의 여부, 학회, ...)에 대해 각각 weight를
        heuristic하게 주어 의사의 전문도를 나타내었습니다. <br> 논문에서는 논문을 많이 작성한 의사는 각 갯수를 정규화 후,
        가중치를 더 주는 방식을 적용하였습니다. 각 속성별 Weight는 차후 시스템에서 사용자가 평점등으로 피드백을 주면
        자동 조절되는 방향으로 모델로 업데이트될 예정입니다.
    </div>
    <br>
    <br>

    <div class="row">
    <h2><p class="font-weight-bold" style="font-size:30px; margin-top: 20px">사용자 증상 입력 Model</p></h2>
    <br>
    <h6> Classes : 교정과, 보철과, 보존과, 치주과, 구강악안면외과, 구강내과, 소아치과</h6>
    </div>
    <br>
    <div class="row">
    <b>개요  </b><br>
    </div>
    <br>
    <div class="row">
    사용자를 증상별로 각 전문분야에 매칭해주기 위해서는 각 분야가 어떤 분야인지 알아야 합니다. <br>
    그리고 학습을 위해서는 전문분야별로 data에 labeling을 해주어야 하는데, 이 때 data에 label을 일일히 붙일 수도 없고
        labeling된 데이터도 없기 때문에 각 과의 특성이 되는 Seed를 정하고, 이를 토대로 data를 수집하여 이를 labeling된 학습데이터로 사용해야 했습니다.
    </div>
    <br>
    <div class="row">
    <b>시도된 모델</b>
    </div>

    <div class="row">
    <div class="alert alert-primary" role="alert" style="width: 700px">
            <b>1) CNN for sentence classification</b>
    </div>
        <b>Accuracy</b> : 79%
    </div>
    <br>
        <div class="row">
            - CNN model은 증상별 전문분야 분류에서도 높은 성능을 보여주었으나,
            실제 사용자가 입력을 하였을 때 애매한 문맥을 가지는 문장을 구분하는 측면에서 self-attention Bi-LSTM
            보다 낮은 점수를 받아 제외되었습니다.
        </div>
    <br>
    <div class="row">
    <div class="alert alert-warning" role="alert" style="width: 700px">
            <b>2) Bi-LSTM Only</b>
    </div>
        <b>Accuracy</b> : 66%
    </div>

    <br>
    <div class="row">
    - 첫 계획은 Bi-LSTM 모델 보다는 Embedding 후 LSTM을 통과시키고 그 후 softmax를 이용하여
    Text classification을 할 생각이 었으나, 정확성을 높이기 위해 Bi-LSTM 모델을 고려하였습니다.<br>
    - Bi-LSTM은 양방향에 LSTM을 적용하는 기법으로, past data와 future data를 고려한다는 점에서
        문맥을 고려할때 좋은 성능을 가집니다. <br>
    - Input으로는 Tokenized된 data들을 Word2Vec으로 임베딩을 진행하여 사용하려 하였습니다.
    그러나 300차원과 Skip-Gram, (min_count=5, window=5) 를 option으로 하였을 때
    임베딩 자체에도 많은 시간이 걸리고 300차원 data는 학습이 너무 오래걸리는 결과를 초래하였습니다.
    따라서 100차원으로 축소하여 속도를 향상시켰습니다. <br>
    </div>
    <br>
    <div class="row">
    <div class="alert alert-danger" role="alert" style="width: 700px">
            <b>3) Bi-LSTM with Attention</b>
        시스템 탑재 모델
    </div>
        <img src="{{ url_for('static',filename='BiLSTM_self_attentive.png') }}" width="700px" height = 600px alt="Attn_Model">
        <b>Accuracy</b> : 77%
    </div>
    <br>
    <div class="row">
        - Bi-LSTM의 각 hidden layer에서 나오는 값으로부터 MaxPooling 대신 Attention을 추가하면 조금 더 문장에서 특징이 되는
        여러 단어를 추출하도록 Weight를 update 할 수 있습니다. 이를 통해 성능을 높이려고 하였습니다.<br>
        - A Structed Self-Attentive Sentence Embedding 논문 및 모델을 참조, 제작하였습니다. <br>
        - Penalization Term을 적용하여, 이 모델에서는 각 문장에서 중요시되는 단어를 찾아내 반영합니다. <br>
        - 추가적으로, DropOut과 Batch Normalization등을 고려하여 성능을 높이고자 하였습니다.<br>
        단어를 Embedding시에 pre-trained Word2Vec 또는 FastText을 적용하는 것도 고려하였으나,
        pytorch의 embedding layer만으로 충분한 성능을 보여줘 적용하지 않았습니다.
    </div>
    <br>
    <br>
</div>